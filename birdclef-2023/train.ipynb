{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "911024a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import os\n",
    "# import pandas as pd\n",
    "# import torchaudio\n",
    "# import torchaudio.transforms as T\n",
    "# import matplotlib.pyplot as plt\n",
    "# import numpy as np\n",
    "# from PIL import Image\n",
    "# from tqdm import tqdm\n",
    "\n",
    "# def save_mel_spectrograms(audio_dir, metadata_csv, output_dir,\n",
    "#                           target_sr=32000, n_mels=128):\n",
    "#     # Load mapping\n",
    "#     metadata = pd.read_csv(metadata_csv)\n",
    "#     label_to_name = (\n",
    "#         metadata[[\"primary_label\", \"common_name\"]]\n",
    "#         .drop_duplicates()\n",
    "#         .set_index(\"primary_label\")[\"common_name\"]\n",
    "#         .to_dict()\n",
    "#     )\n",
    "\n",
    "#     mel_transform = T.MelSpectrogram(\n",
    "#         sample_rate=target_sr,\n",
    "#         n_mels=n_mels\n",
    "#     )\n",
    "\n",
    "#     if not os.path.exists(output_dir):\n",
    "#         os.makedirs(output_dir)\n",
    "\n",
    "#     # Iterate over folders (primary labels)\n",
    "#     for label_folder in tqdm(os.listdir(audio_dir), desc=\"Processing labels\"):\n",
    "#         folder_path = os.path.join(audio_dir, label_folder)\n",
    "#         if not os.path.isdir(folder_path):\n",
    "#             continue\n",
    "\n",
    "#         common_name = label_to_name.get(label_folder, label_folder)\n",
    "#         common_folder = os.path.join(output_dir, common_name)\n",
    "#         os.makedirs(common_folder, exist_ok=True)\n",
    "\n",
    "#         for fname in os.listdir(folder_path):\n",
    "#             if not fname.endswith(\".ogg\"):\n",
    "#                 continue\n",
    "\n",
    "#             file_path = os.path.join(folder_path, fname)\n",
    "#             waveform, sr = torchaudio.load(file_path)\n",
    "\n",
    "#             # Resample if needed\n",
    "#             if sr != target_sr:\n",
    "#                 resampler = torchaudio.transforms.Resample(orig_freq=sr, new_freq=target_sr)\n",
    "#                 waveform = resampler(waveform)\n",
    "\n",
    "#             # Convert to mono (optional)\n",
    "#             if waveform.shape[0] > 1:\n",
    "#                 waveform = waveform.mean(dim=0, keepdim=True)\n",
    "\n",
    "#             # Mel spectrogram\n",
    "#             mel_spec = mel_transform(waveform)\n",
    "#             mel_spec = torchaudio.functional.amplitude_to_DB(\n",
    "#                         mel_spec, \n",
    "#                         multiplier=20.0, \n",
    "#                         amin=1e-10, \n",
    "#                         db_multiplier=0.0\n",
    "#                     )\n",
    "\n",
    "#             # Normalize to 0–255 and convert to image\n",
    "#             mel_spec = mel_spec.squeeze().numpy()\n",
    "#             mel_spec -= mel_spec.min()\n",
    "#             mel_spec /= mel_spec.max()\n",
    "#             mel_spec = (mel_spec * 255).astype(np.uint8)\n",
    "\n",
    "#             # Save as PNG\n",
    "#             img = Image.fromarray(mel_spec)\n",
    "#             img = img.convert(\"L\")  # grayscale\n",
    "#             out_name = os.path.splitext(fname)[0] + \".png\"\n",
    "#             img.save(os.path.join(common_folder, out_name))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0770c2ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import os\n",
    "# import shutil\n",
    "# import random\n",
    "# from pathlib import Path\n",
    "\n",
    "# # Paths\n",
    "# DATASET_DIR = Path(\"spectrogram_dataset\")\n",
    "# OUTPUT_DIR = Path(\"splitted_dataset\")\n",
    "# TRAIN_DIR = OUTPUT_DIR / \"train\"\n",
    "# TEST_DIR = OUTPUT_DIR / \"test\"\n",
    "\n",
    "# # Split ratio\n",
    "# test_ratio = 0.2\n",
    "# random.seed(42)\n",
    "\n",
    "# # Create output directories\n",
    "# for split_dir in [TRAIN_DIR, TEST_DIR]:\n",
    "#     split_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# # Iterate over each label folder\n",
    "# for label_dir in DATASET_DIR.iterdir():\n",
    "#     if label_dir.is_dir():\n",
    "#         label = label_dir.name\n",
    "#         files = list(label_dir.glob(\"*.png\"))\n",
    "#         random.shuffle(files)\n",
    "\n",
    "#         # Calculate split index\n",
    "#         split_idx = int(len(files) * (1 - test_ratio))\n",
    "#         train_files = files[:split_idx]\n",
    "#         test_files = files[split_idx:]\n",
    "\n",
    "#         # Create label subdirectories\n",
    "#         (TRAIN_DIR / label).mkdir(exist_ok=True)\n",
    "#         (TEST_DIR / label).mkdir(exist_ok=True)\n",
    "\n",
    "#         # Copy files\n",
    "#         for f in train_files:\n",
    "#             shutil.copy(f, TRAIN_DIR / label / f.name)\n",
    "\n",
    "#         for f in test_files:\n",
    "#             shutil.copy(f, TEST_DIR / label / f.name)\n",
    "\n",
    "# print(\"✅ Done splitting dataset.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "50062854",
   "metadata": {},
   "outputs": [],
   "source": [
    "config = {\n",
    "    \"use_aug\" : False,\n",
    "    \"num_classes\" : 264,\n",
    "    \"batch_size\" : 64,\n",
    "    \"epochs\" : 1,\n",
    "    \"PRECISION\" : 16,\n",
    "    \"PATIENCE\" : 8,    \n",
    "    \"seed\" : 64,\n",
    "    \"model\" : \"tf_efficientnet_b1_ns\",\n",
    "    \"pretrained\" : True,            \n",
    "    \"weight_decay\" : 1e-3,\n",
    "    \"use_mixup\" : True,\n",
    "    \"mixup_alpha\" : 0.6,  \n",
    "\n",
    "    \"train_images\" : \"/mnt/Stuff/phd_projects/birdclef-2023/splitted_dataset/train\",\n",
    "    \"valid_images\" : \"/mnt/Stuff/phd_projects/birdclef-2023/splitted_dataset/test\",\n",
    "    \"train_path\" : \"/kaggle/input/bc2023-train-val-df/train.csv\",\n",
    "    \"valid_path\" : \"/kaggle/input/bc2023-train-val-df/valid.csv\",\n",
    "    \n",
    "    \"SR\" : 32000,\n",
    "    \"DURATION\" : 5,\n",
    "    \"MAX_READ_SAMPLES\" : 5,\n",
    "    \"LR\" : 1e-3\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d58fcc23",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from PIL import Image\n",
    "import torch\n",
    "from torch.utils.data import Dataset\n",
    "\n",
    "class BirdSpectrogramDataset(Dataset):\n",
    "    def __init__(self, spectrogram_dir, transform=None):\n",
    "        \"\"\"\n",
    "        spectrogram_dir: root directory with folders per common name\n",
    "        transform: torchvision transforms to apply to images\n",
    "        \"\"\"\n",
    "        self.spectrogram_dir = spectrogram_dir\n",
    "        self.transform = transform\n",
    "\n",
    "        # Build class index\n",
    "        self.classes = sorted(os.listdir(spectrogram_dir))\n",
    "        self.class_to_idx = {cls_name: idx for idx, cls_name in enumerate(self.classes)}\n",
    "\n",
    "        # Build file list\n",
    "        self.samples = []\n",
    "        for cls_name in self.classes:\n",
    "            folder = os.path.join(spectrogram_dir, cls_name)\n",
    "            for fname in os.listdir(folder):\n",
    "                if fname.endswith(\".png\"):\n",
    "                    self.samples.append({\n",
    "                        \"path\": os.path.join(folder, fname),\n",
    "                        \"label\": cls_name\n",
    "                    })\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.samples)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        sample = self.samples[idx]\n",
    "        img = Image.open(sample[\"path\"]).convert(\"L\")\n",
    "        label_name = sample[\"label\"]\n",
    "        label_idx = self.class_to_idx[label_name]\n",
    "\n",
    "        if self.transform:\n",
    "            img = self.transform(img)\n",
    "\n",
    "        return img, label_idx\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ff2c9ba5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Label to index mapping:\n",
      "{'Abyssinian Thrush': 0, 'African Bare-eyed Thrush': 1, 'African Black-headed Oriole': 2, 'African Blue Flycatcher': 3, 'African Darter': 4, 'African Dusky Flycatcher': 5, 'African Emerald Cuckoo': 6, 'African Fish-Eagle': 7, 'African Goshawk': 8, 'African Gray Flycatcher': 9, 'African Gray Hornbill': 10, 'African Green-Pigeon': 11, 'African Jacana': 12, 'African Paradise-Flycatcher': 13, 'African Pied Wagtail': 14, 'African Pygmy Kingfisher': 15, 'African Sacred Ibis': 16, 'African Thrush': 17, 'Amethyst Sunbird': 18, 'Augur Buzzard': 19, 'Baglafecht Weaver': 20, 'Barn Swallow': 21, 'Beautiful Sunbird': 22, 'Black Crake': 23, 'Black Cuckoo': 24, 'Black Kite': 25, 'Black Sawwing': 26, 'Black-and-white Mannikin': 27, 'Black-and-white-casqued Hornbill': 28, 'Black-backed Puffback': 29, 'Black-collared Apalis': 30, 'Black-crowned Tchagra': 31, 'Black-faced Rufous-Warbler': 32, 'Black-fronted Bushshrike': 33, 'Black-headed Gonolek': 34, 'Black-headed Heron': 35, 'Black-necked Weaver': 36, 'Black-tailed Oriole': 37, 'Black-throated Apalis': 38, 'Black-throated Barbet': 39, 'Black-winged Lapwing': 40, 'Blacksmith Lapwing': 41, 'Blue-cheeked Bee-eater': 42, 'Blue-naped Mousebird': 43, 'Blue-spotted Wood-Dove': 44, 'Brimstone Canary': 45, 'Bristle-crowned Starling': 46, 'Bronze Mannikin': 47, 'Bronze Sunbird': 48, 'Brown Babbler': 49, 'Brown Woodland-Warbler': 50, 'Brown-capped Weaver': 51, 'Brown-chested Alethe': 52, 'Brown-crowned Tchagra': 53, 'Brown-tailed Chat': 54, 'Brown-throated Wattle-eye': 55, 'Brubru': 56, 'Buff-bellied Warbler': 57, 'Buff-throated Apalis': 58, \"Cabanis's Greenbul\": 59, 'Cape Robin-Chat': 60, 'Cardinal Woodpecker': 61, 'Cattle Egret': 62, 'Chestnut Sparrow': 63, 'Chestnut Weaver': 64, 'Chestnut-throated Apalis': 65, 'Chinspot Batis': 66, \"Chubb's Cisticola\": 67, 'Cinnamon Bracken-Warbler': 68, 'Cinnamon-chested Bee-eater': 69, 'Collared Sunbird': 70, 'Common Bulbul': 71, 'Common Buzzard': 72, 'Common House-Martin': 73, 'Common Sandpiper': 74, 'Crested Francolin': 75, 'Crowned Eagle': 76, 'Crowned Hornbill': 77, \"D'Arnaud's Barbet\": 78, 'Dideric Cuckoo': 79, 'Double-toothed Barbet': 80, 'Dusky Turtle-Dove': 81, 'Eastern Double-collared Sunbird': 82, 'Eastern Mountain Greenbul': 83, 'Eastern Violet-backed Sunbird': 84, 'Egyptian Goose': 85, 'Emerald-spotted Wood-Dove': 86, 'Equatorial Akalat': 87, 'Eurasian Hoopoe': 88, 'European Bee-eater': 89, 'Fan-tailed Raven': 90, 'Fan-tailed Widowbird': 91, \"Fischer's Lovebird\": 92, 'Fork-tailed Drongo': 93, 'Gabar Goshawk': 94, 'Garganey': 95, 'Golden-backed Weaver': 96, 'Golden-breasted Bunting': 97, 'Golden-breasted Starling': 98, 'Goliath Heron': 99, 'Gray Apalis': 100, 'Gray Crowned-Crane': 101, 'Gray Wren-Warbler': 102, 'Gray-backed Camaroptera': 103, 'Gray-backed Fiscal': 104, 'Gray-capped Warbler': 105, 'Gray-headed Bushshrike': 106, 'Gray-headed Kingfisher': 107, 'Gray-headed Nigrita': 108, 'Gray-throated Barbet': 109, 'Great Cormorant': 110, 'Great Egret': 111, 'Greater Blue-eared Starling': 112, 'Green Woodhoopoe': 113, 'Green-backed Camaroptera': 114, 'Green-headed Sunbird': 115, 'Green-winged Pytilia': 116, 'Hadada Ibis': 117, 'Hamerkop': 118, \"Hartlaub's Turaco\": 119, 'Helmeted Guineafowl': 120, \"Hinde's Pied-Babbler\": 121, \"Hunter's Cisticola\": 122, \"Hunter's Sunbird\": 123, 'Joyful Greenbul': 124, 'Kenya Rufous Sparrow': 125, 'Kikuyu White-eye': 126, \"Klaas's Cuckoo\": 127, 'Laughing Dove': 128, \"Lawrence's Goldfinch\": 129, 'Lesser Masked-Weaver': 130, 'Lesser Striped Swallow': 131, 'Little Bee-eater': 132, 'Little Egret': 133, 'Little Swift': 134, 'Little Weaver': 135, 'Long-crested Eagle': 136, 'Long-tailed Cormorant': 137, 'Long-toed Lapwing': 138, \"Lühder's Bushshrike\": 139, \"Mackinnon's Shrike\": 140, 'Madagascar Bee-eater': 141, 'Malachite Kingfisher': 142, 'Marabou Stork': 143, 'Mariqua Sunbird': 144, \"Meyer's Parrot\": 145, 'Mocking Cliff-Chat': 146, 'Mountain Wagtail': 147, 'Mourning Collared-Dove': 148, 'Mouse-colored Penduline-Tit': 149, 'Northern Black-Flycatcher': 150, 'Northern Brownbul': 151, 'Northern Crombec': 152, 'Northern Double-collared Sunbird': 153, 'Northern Fiscal': 154, 'Northern Gray-headed Sparrow': 155, 'Northern Puffback': 156, 'Northern Red-billed Hornbill': 157, 'Nubian Woodpecker': 158, 'Pale Flycatcher': 159, 'Pale Prinia': 160, 'Pale White-eye': 161, 'Parrot-billed Sparrow': 162, 'Pied Crow': 163, 'Pied Kingfisher': 164, 'Pin-tailed Whydah': 165, 'Purple Grenadier': 166, 'Pygmy Batis': 167, 'Quailfinch': 168, 'Rattling Cisticola': 169, 'Red-and-yellow Barbet': 170, 'Red-backed Scrub-Robin': 171, 'Red-billed Firefinch': 172, 'Red-billed Oxpecker': 173, 'Red-cheeked Cordonbleu': 174, 'Red-chested Cuckoo': 175, 'Red-eyed Dove': 176, 'Red-faced Crombec': 177, 'Red-fronted Barbet': 178, 'Red-fronted Prinia': 179, 'Red-fronted Tinkerbird': 180, 'Red-headed Bluebill': 181, 'Red-headed Weaver': 182, 'Red-rumped Swallow': 183, 'Red-winged Starling': 184, \"Reichenow's Seedeater\": 185, 'Ring-necked Dove': 186, 'Rock Martin': 187, \"Ross's Turaco\": 188, 'Rufous Chatterer': 189, \"Rüppell's Starling\": 190, 'Scaly-throated Honeyguide': 191, 'Scarlet-chested Sunbird': 192, \"Shelley's Starling\": 193, 'Silvery-cheeked Hornbill': 194, 'Singing Cisticola': 195, 'Slate-colored Boubou': 196, 'Slender-billed Greenbul': 197, 'Slender-tailed Nightjar': 198, 'Snowy-crowned Robin-Chat': 199, 'Somali Tit': 200, 'Sombre Greenbul': 201, 'Southern Black-Flycatcher': 202, 'Southern Citril': 203, 'Southern Fiscal': 204, 'Speckle-fronted Weaver': 205, 'Speckled Mousebird': 206, 'Speckled Pigeon': 207, 'Spectacled Weaver': 208, 'Spot-flanked Barbet': 209, 'Spotted Morning-Thrush': 210, 'Spur-winged Lapwing': 211, 'Squacco Heron': 212, 'Streaky Seedeater': 213, 'Striated Heron': 214, \"Stuhlmann's Starling\": 215, 'Sulphur-breasted Bushshrike': 216, 'Superb Starling': 217, 'Tacazze Sunbird': 218, 'Tambourine Dove': 219, 'Tawny-flanked Prinia': 220, 'Thrush Nightingale': 221, 'Tropical Boubou': 222, 'Variable Sunbird': 223, 'Village Weaver': 224, 'Violet-backed Starling': 225, 'Vitelline Masked-Weaver': 226, \"Waller's Starling\": 227, 'Western Yellow Wagtail': 228, 'White Helmetshrike': 229, 'White-bellied Canary': 230, 'White-bellied Go-away-bird': 231, 'White-bellied Tit': 232, 'White-browed Coucal': 233, 'White-browed Crombec': 234, 'White-browed Robin-Chat': 235, 'White-browed Sparrow-Weaver': 236, 'White-chinned Prinia': 237, 'White-crested Turaco': 238, 'White-eyed Slaty-Flycatcher': 239, 'White-fronted Bee-eater': 240, 'White-headed Buffalo-Weaver': 241, 'White-headed Sawwing': 242, 'White-rumped Shrike': 243, 'White-throated Bee-eater': 244, 'Willow Warbler': 245, 'Wire-tailed Swallow': 246, 'Wood Sandpiper': 247, 'Woodland Kingfisher': 248, 'Yellow Bishop': 249, 'Yellow-bellied Eremomela': 250, 'Yellow-bellied Greenbul': 251, 'Yellow-billed Barbet': 252, 'Yellow-billed Duck': 253, 'Yellow-billed Stork': 254, 'Yellow-breasted Apalis': 255, 'Yellow-crowned Canary': 256, 'Yellow-fronted Canary': 257, 'Yellow-necked Francolin': 258, 'Yellow-rumped Tinkerbird': 259, 'Yellow-spotted Barbet': 260, 'Yellow-spotted Bush Sparrow': 261, 'Yellow-throated Greenbul': 262, 'Yellow-whiskered Greenbul': 263}\n"
     ]
    }
   ],
   "source": [
    "def generate_label_map(root_dir):\n",
    "    \"\"\"\n",
    "    Generates a mapping from string labels to integer indices\n",
    "    based on the subfolder names in root_dir.\n",
    "    \"\"\"\n",
    "    # Get all subfolders (each represents a class)\n",
    "    labels = sorted([d for d in os.listdir(root_dir) if os.path.isdir(os.path.join(root_dir, d))])\n",
    "    \n",
    "    # Create the mapping\n",
    "    label_to_idx = {label: idx for idx, label in enumerate(labels)}\n",
    "    idx_to_label = {idx: label for label, idx in label_to_idx.items()}\n",
    "    \n",
    "    return label_to_idx, idx_to_label\n",
    "\n",
    "# Example usage\n",
    "root_dir = \"spectrogram_dataset\"  # folder where each class has its own subfolder\n",
    "label_to_idx, idx_to_label = generate_label_map(root_dir)\n",
    "\n",
    "print(\"Label to index mapping:\")\n",
    "print(label_to_idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9879fda0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "from torchvision import transforms\n",
    "\n",
    "audio_dir = \"/mnt/Stuff/phd_projects/birdclef-2023/splitted_dataset/train\"\n",
    "metadata_csv = \"/mnt/Stuff/phd_projects/birdclef-2023/train_metadata.csv\"\n",
    "train_dir = \"/mnt/Stuff/phd_projects/birdclef-2023/splitted_dataset/train\"\n",
    "test_dir = \"/mnt/Stuff/phd_projects/birdclef-2023/splitted_dataset/test\"\n",
    "\n",
    "# Step 1: Preprocess & save spectrograms\n",
    "# save_mel_spectrograms(audio_dir, metadata_csv, spectrogram_dir)\n",
    "\n",
    "# Step 2: Create dataset and dataloader\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),  # for CNN input\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.5], std=[0.5])\n",
    "])\n",
    "\n",
    "train_dataset = BirdSpectrogramDataset(train_dir, transform=transform)\n",
    "train_dataloader = DataLoader(train_dataset, batch_size=16, shuffle=True)\n",
    "\n",
    "test_dataset = BirdSpectrogramDataset(test_dir, transform=transform)\n",
    "test_dataloader = DataLoader(test_dataset, batch_size=16, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1edd575a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sklearn.metrics\n",
    "import pandas as pd\n",
    "\n",
    "def padded_cmap(solution, submission, padding_factor=5):\n",
    "    solution = solution#.drop(['row_id'], axis=1, errors='ignore')\n",
    "    submission = submission#.drop(['row_id'], axis=1, errors='ignore')\n",
    "    new_rows = []\n",
    "    for i in range(padding_factor):\n",
    "        new_rows.append([1 for i in range(len(solution.columns))])\n",
    "    new_rows = pd.DataFrame(new_rows)\n",
    "    new_rows.columns = solution.columns\n",
    "    padded_solution = pd.concat([solution, new_rows]).reset_index(drop=True).copy()\n",
    "    padded_submission = pd.concat([submission, new_rows]).reset_index(drop=True).copy()\n",
    "    score = sklearn.metrics.average_precision_score(\n",
    "        padded_solution.values,\n",
    "        padded_submission.values,\n",
    "        average='macro',\n",
    "    )\n",
    "    return score\n",
    "\n",
    "def map_score(solution, submission):\n",
    "    solution = solution#.drop(['row_id'], axis=1, errors='ignore')\n",
    "    submission = submission#.drop(['row_id'], axis=1, errors='ignore')\n",
    "    score = sklearn.metrics.average_precision_score(\n",
    "        solution.values,\n",
    "        submission.values,\n",
    "        average='micro',\n",
    "    )\n",
    "    return score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "187e9817",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "from torchvision.models import efficientnet_b0\n",
    "from torchvision.models.resnet import resnet18\n",
    "\n",
    "class BirdClefModel(nn.Module):\n",
    "    def __init__(self, model_name, num_classes, pretrained=True):\n",
    "        super().__init__()\n",
    "        self.num_classes = num_classes\n",
    "\n",
    "        self.backbone = None\n",
    "        self.in_features = None\n",
    "\n",
    "        # Replace classifier head depending on model type\n",
    "        if 'resnet' in model_name:\n",
    "            self.backbone = resnet18(num_classes=num_classes)\n",
    "            self.in_features = self.backbone.fc.in_features\n",
    "            self.backbone.fc = nn.Linear(self.in_features, num_classes)\n",
    "            \n",
    "            self.backbone.bn1 = nn.BatchNorm2d(64)\n",
    "            self.backbone.conv1 = nn.Conv2d(1, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
    "        elif 'efficientnet' in model_name:\n",
    "            self.backbone = efficientnet_b0(num_classes=num_classes)\n",
    "            self.in_features = 1000\n",
    "\n",
    "            self.backbone.features[0][0] = nn.Conv2d(1, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
    "        else:\n",
    "            raise ValueError(f\"Unsupported model type for: {model_name}\")\n",
    "        \n",
    "        if self.in_features is None:    \n",
    "            raise ValueError(\"In Features cannot be None\")\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.backbone(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4df900bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "class FakeQuantize(nn.Module):\n",
    "    def __init__(self, num_bits=8):\n",
    "        super().__init__()\n",
    "        self.num_bits = num_bits\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Calculate min and max per tensor\n",
    "        x_min = x.min()\n",
    "        x_max = x.max()\n",
    "        \n",
    "        qmin = 0\n",
    "        qmax = 2 ** self.num_bits - 1\n",
    "\n",
    "        # Scale and zero point\n",
    "        scale = (x_max - x_min) / (qmax - qmin + 1e-8)\n",
    "        zero_point = qmin - x_min / (scale + 1e-8)\n",
    "        zero_point = zero_point.round().clamp(qmin, qmax)\n",
    "\n",
    "        # Quantize-dequantize\n",
    "        q_x = ((x / scale + zero_point).round().clamp(qmin, qmax) - zero_point) * scale\n",
    "        return q_x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b7d4d89c",
   "metadata": {},
   "outputs": [],
   "source": [
    "class QuantizedLayer(nn.Module):\n",
    "    def __init__(self, layer, num_bits=8):\n",
    "        super().__init__()\n",
    "        self.layer = layer\n",
    "        self.fake_quant = FakeQuantize(num_bits)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Fake-quantize input\n",
    "        x = self.fake_quant(x)\n",
    "        # Apply layer\n",
    "        x = self.layer(x)\n",
    "        # Fake-quantize output\n",
    "        x = self.fake_quant(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6f1c7c3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def apply_fake_quant(module, num_bits=8):\n",
    "    \"\"\"\n",
    "    Recursively replaces Conv2d and Linear layers with quantized versions.\n",
    "    \"\"\"\n",
    "    for name, child in module.named_children():\n",
    "        if isinstance(child, nn.Conv2d) or isinstance(child, nn.Linear):\n",
    "            # Wrap original layer with fake quant for weights and activations\n",
    "            setattr(module, name, QuantizedLayer(child, num_bits=num_bits))\n",
    "        else:\n",
    "            apply_fake_quant(child, num_bits)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a96aca7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "\n",
    "model = BirdClefModel(\"efficientnet\", 264).to(device)\n",
    "\n",
    "apply_fake_quant(model, num_bits=8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "232aece1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from executorch.backends.xnnpack.quantizer.xnnpack_quantizer import (\n",
    "#   get_symmetric_quantization_config,\n",
    "#   XNNPACKQuantizer,\n",
    "# )\n",
    "# from torchao.quantization.pt2e.quantize_pt2e import (\n",
    "#   prepare_qat_pt2e,\n",
    "#   convert_pt2e,\n",
    "#   prepare_pt2e\n",
    "# )\n",
    "\n",
    "# torch.save(model.state_dict(), 'orig_model.pth')\n",
    "\n",
    "# model.eval()\n",
    "\n",
    "# quantizer = XNNPACKQuantizer()\n",
    "\n",
    "# sample_inputs = (torch.randn(2, 1, 224, 224).to(device),)\n",
    "\n",
    "# exported_model = torch.export.export( \n",
    "#     model, \n",
    "#     sample_inputs).module()\n",
    "\n",
    "# quantizer.set_global(get_symmetric_quantization_config(is_qat=True))\n",
    "\n",
    "# model = prepare_qat_pt2e(exported_model, quantizer)\n",
    "\n",
    "# torchao.quantization.pt2e.move_exported_model_to_eval(model)\n",
    "\n",
    "# quantizer.set_global(get_symmetric_quantization_config())\n",
    "# model = prepare_pt2e(exported_model, quantizer)\n",
    "# quantized = convert_pt2e(model)\n",
    "\n",
    "# torch.save(quantized.state_dict(), 'best_model_qauantized.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "ad8d9012",
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "optimizer = torch.optim.AdamW(\n",
    "            filter(lambda p: p.requires_grad, model.parameters()), \n",
    "            lr=config['LR'],\n",
    "            weight_decay=config['weight_decay']\n",
    "        )\n",
    "    \n",
    "# lr_scheduler = CosineAnnealingWarmRestarts(\n",
    "#                     optimizer, \n",
    "#                     T_0=config['epochs'], \n",
    "#                     T_mult=1, \n",
    "#                     eta_min=1e-6, \n",
    "#                     last_epoch=-1\n",
    "#                 )\n",
    "\n",
    "lr_scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='min', patience=3, factor=0.2)\n",
    "\n",
    "birds = list(label_to_idx.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "547266a1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch number: 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 841/841 [05:43<00:00,  2.45it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 5.6591 | Train Acc: 0.0039\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validating: 100%|██████████| 219/219 [00:40<00:00,  5.38it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val Loss: 6.3838 | Val Acc: 0.0037\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "train_acc_history = []\n",
    "val_acc_history = []\n",
    "train_losses = []\n",
    "val_losses = []\n",
    "\n",
    "val_df = pd.DataFrame(columns=birds)\n",
    "pred_df = pd.DataFrame(columns=birds)\n",
    "\n",
    "for epoch in range(config['epochs']):\n",
    "    # =========================== TRAINING =========================== #\n",
    "    model.train()\n",
    "    total_train_loss, total_train_acc, n_train_batches = 0.0, 0.0, 0\n",
    "    print(f'Epoch number: {epoch}')\n",
    "\n",
    "    for images, targets in tqdm(train_dataloader, desc=\"Training\"):\n",
    "        images, targets = images.to(device), targets.to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        logits = model(images)\n",
    "\n",
    "        # print(\"TRAIN\")\n",
    "        # print(logits)\n",
    "\n",
    "        loss = criterion(logits, targets)\n",
    "\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # accuracy\n",
    "        preds = torch.argmax(logits, dim=1)\n",
    "        acc = (preds == targets).float().mean()\n",
    "\n",
    "        total_train_loss += loss.item()\n",
    "        total_train_acc += acc.item()\n",
    "        n_train_batches += 1\n",
    "        \n",
    "\n",
    "    avg_loss = total_train_loss / n_train_batches\n",
    "    avg_acc = total_train_acc / n_train_batches\n",
    "    train_acc_history.append(avg_acc)\n",
    "    train_losses.append(avg_loss)\n",
    "\n",
    "    print(f\"Train Loss: {avg_loss:.4f} | Train Acc: {avg_acc:.4f}\")\n",
    "\n",
    "    # =========================== VALIDATION =========================== #\n",
    "    model.eval()\n",
    "    \n",
    "    total_val_loss, total_val_acc, n_val_batches = 0.0, 0.0, 0\n",
    "    all_logits, all_targets = [], []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for images, targets in tqdm(test_dataloader, desc=\"Validating\"):\n",
    "            images, targets = images.to(device), targets.to(device)\n",
    "            logits = model(images)\n",
    "\n",
    "            # print(\"VALIDATION\")\n",
    "            # print(logits)\n",
    "                \n",
    "            loss = criterion(logits, targets)\n",
    "\n",
    "            preds = torch.argmax(logits, dim=1)\n",
    "            acc = (preds == targets).float().mean()\n",
    "\n",
    "            total_val_loss += loss.item()\n",
    "            total_val_acc += acc.item()\n",
    "            n_val_batches += 1\n",
    "\n",
    "        avg_loss = total_val_loss / n_val_batches\n",
    "        avg_acc = total_val_acc / n_val_batches\n",
    "        val_acc_history.append(avg_acc)\n",
    "        val_losses.append(avg_loss)\n",
    "\n",
    "        print(f\"Val Loss: {avg_loss:.4f} | Val Acc: {avg_acc:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "53758b6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "orig_model = BirdClefModel(\"efficientnet\", 264)\n",
    "torch.save(orig_model.state_dict(), 'orig_model.pth')\n",
    "\n",
    "torch.save(model.state_dict(), 'qat_model.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "7a2f17a6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /tmp/tmpmntitsrb/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /tmp/tmpmntitsrb/assets\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "W0000 00:00:1760797964.924407    8075 tf_tfl_flatbuffer_helpers.cc:364] Ignored output_format.\n",
      "W0000 00:00:1760797964.924427    8075 tf_tfl_flatbuffer_helpers.cc:367] Ignored drop_control_dependency.\n",
      "2025-10-18 20:32:44.924690: I tensorflow/cc/saved_model/reader.cc:83] Reading SavedModel from: /tmp/tmpmntitsrb\n",
      "2025-10-18 20:32:44.928897: I tensorflow/cc/saved_model/reader.cc:52] Reading meta graph with tags { serve }\n",
      "2025-10-18 20:32:44.928906: I tensorflow/cc/saved_model/reader.cc:147] Reading SavedModel debug info (if present) from: /tmp/tmpmntitsrb\n",
      "I0000 00:00:1760797964.963965    8075 mlir_graph_optimization_pass.cc:437] MLIR V1 optimization pass is not enabled\n",
      "2025-10-18 20:32:44.969347: I tensorflow/cc/saved_model/loader.cc:236] Restoring SavedModel bundle.\n",
      "2025-10-18 20:32:45.250749: I tensorflow/cc/saved_model/loader.cc:220] Running initialization op on SavedModel bundle at path: /tmp/tmpmntitsrb\n",
      "2025-10-18 20:32:45.317479: I tensorflow/cc/saved_model/loader.cc:471] SavedModel load for tags { serve }; Status: success: OK. Took 392792 microseconds.\n",
      "2025-10-18 20:32:45.375076: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:269] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\n",
      "2025-10-18 20:32:48.056487: I tensorflow/compiler/mlir/lite/flatbuffer_export.cc:4150] Estimated count of arithmetic ops: 2.331 G  ops, equivalently 1.165 G  MACs\n"
     ]
    }
   ],
   "source": [
    "# from executorch.backends.xnnpack.quantizer.xnnpack_quantizer import (\n",
    "#     get_symmetric_quantization_config,\n",
    "#     XNNPACKQuantizer,\n",
    "# )\n",
    "\n",
    "# from torchao.quantization.pt2e.quantize_pt2e import (\n",
    "#   prepare_qat_pt2e,\n",
    "# )\n",
    "\n",
    "# example_inputs = (torch.rand(1, 1, 224, 224),)\n",
    "# float_model = BirdClefModel(\"efficientnet\", 264)\n",
    "# float_model.eval()\n",
    "\n",
    "# exported_model = torch.export.export(float_model, example_inputs).module()\n",
    "\n",
    "# quantizer = XNNPACKQuantizer()\n",
    "# quantizer.set_global(get_symmetric_quantization_config(is_qat=True))\n",
    "\n",
    "# prepared_model = prepare_qat_pt2e(exported_model, quantizer)\n",
    "# prepared_model.load_state_dict(torch.load(\"best_model_qat1.pth\"))\n",
    "import ai_edge_torch\n",
    "\n",
    "sample_inputs = (torch.randn(2, 1, 224, 224),)\n",
    "edge_model = ai_edge_torch.convert(orig_model.eval(), sample_inputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "64b0e1c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "edge_model.export('birdcall_model.tflite')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "9909714e",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(train_losses, label='Training Loss')\n",
    "plt.plot(val_losses, label='Validation Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.title('Training & Validation Losses')\n",
    "plt.legend()\n",
    "plt.savefig('train_val_loss_plot.png')\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "b7f1b345",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(train_acc_history, label='Training Accuracy')\n",
    "plt.plot(val_acc_history, label='Validation Accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.title('Training & Validation Accuracy')\n",
    "plt.ylim(0, 1)\n",
    "plt.legend()\n",
    "plt.savefig('accuracy_plot.png')\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "73d77574",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mushahid/anaconda3/envs/esp32-env/lib/python3.11/site-packages/torch/fx/graph.py:1157: UserWarning: erase_node(batch_norm_98) on an already erased node\n",
      "  warnings.warn(f\"erase_node({to_erase}) on an already erased node\")\n",
      "/home/mushahid/anaconda3/envs/esp32-env/lib/python3.11/site-packages/torch/fx/graph.py:1157: UserWarning: erase_node(batch_norm_99) on an already erased node\n",
      "  warnings.warn(f\"erase_node({to_erase}) on an already erased node\")\n",
      "/home/mushahid/anaconda3/envs/esp32-env/lib/python3.11/site-packages/torch/fx/graph.py:1157: UserWarning: erase_node(batch_norm_100) on an already erased node\n",
      "  warnings.warn(f\"erase_node({to_erase}) on an already erased node\")\n",
      "/home/mushahid/anaconda3/envs/esp32-env/lib/python3.11/site-packages/torch/fx/graph.py:1157: UserWarning: erase_node(batch_norm_101) on an already erased node\n",
      "  warnings.warn(f\"erase_node({to_erase}) on an already erased node\")\n",
      "/home/mushahid/anaconda3/envs/esp32-env/lib/python3.11/site-packages/torch/fx/graph.py:1157: UserWarning: erase_node(batch_norm_102) on an already erased node\n",
      "  warnings.warn(f\"erase_node({to_erase}) on an already erased node\")\n",
      "/home/mushahid/anaconda3/envs/esp32-env/lib/python3.11/site-packages/torch/fx/graph.py:1157: UserWarning: erase_node(batch_norm_103) on an already erased node\n",
      "  warnings.warn(f\"erase_node({to_erase}) on an already erased node\")\n",
      "/home/mushahid/anaconda3/envs/esp32-env/lib/python3.11/site-packages/torch/fx/graph.py:1157: UserWarning: erase_node(batch_norm_104) on an already erased node\n",
      "  warnings.warn(f\"erase_node({to_erase}) on an already erased node\")\n",
      "/home/mushahid/anaconda3/envs/esp32-env/lib/python3.11/site-packages/torch/fx/graph.py:1157: UserWarning: erase_node(batch_norm_105) on an already erased node\n",
      "  warnings.warn(f\"erase_node({to_erase}) on an already erased node\")\n",
      "/home/mushahid/anaconda3/envs/esp32-env/lib/python3.11/site-packages/torch/fx/graph.py:1157: UserWarning: erase_node(batch_norm_106) on an already erased node\n",
      "  warnings.warn(f\"erase_node({to_erase}) on an already erased node\")\n",
      "/home/mushahid/anaconda3/envs/esp32-env/lib/python3.11/site-packages/torch/fx/graph.py:1157: UserWarning: erase_node(batch_norm_107) on an already erased node\n",
      "  warnings.warn(f\"erase_node({to_erase}) on an already erased node\")\n",
      "/home/mushahid/anaconda3/envs/esp32-env/lib/python3.11/site-packages/torch/fx/graph.py:1157: UserWarning: erase_node(batch_norm_108) on an already erased node\n",
      "  warnings.warn(f\"erase_node({to_erase}) on an already erased node\")\n",
      "/home/mushahid/anaconda3/envs/esp32-env/lib/python3.11/site-packages/torch/fx/graph.py:1157: UserWarning: erase_node(batch_norm_109) on an already erased node\n",
      "  warnings.warn(f\"erase_node({to_erase}) on an already erased node\")\n",
      "/home/mushahid/anaconda3/envs/esp32-env/lib/python3.11/site-packages/torch/fx/graph.py:1157: UserWarning: erase_node(batch_norm_110) on an already erased node\n",
      "  warnings.warn(f\"erase_node({to_erase}) on an already erased node\")\n",
      "/home/mushahid/anaconda3/envs/esp32-env/lib/python3.11/site-packages/torch/fx/graph.py:1157: UserWarning: erase_node(batch_norm_111) on an already erased node\n",
      "  warnings.warn(f\"erase_node({to_erase}) on an already erased node\")\n",
      "/home/mushahid/anaconda3/envs/esp32-env/lib/python3.11/site-packages/torch/fx/graph.py:1157: UserWarning: erase_node(batch_norm_112) on an already erased node\n",
      "  warnings.warn(f\"erase_node({to_erase}) on an already erased node\")\n",
      "/home/mushahid/anaconda3/envs/esp32-env/lib/python3.11/site-packages/torch/fx/graph.py:1157: UserWarning: erase_node(batch_norm_113) on an already erased node\n",
      "  warnings.warn(f\"erase_node({to_erase}) on an already erased node\")\n",
      "/home/mushahid/anaconda3/envs/esp32-env/lib/python3.11/site-packages/torch/fx/graph.py:1157: UserWarning: erase_node(batch_norm_114) on an already erased node\n",
      "  warnings.warn(f\"erase_node({to_erase}) on an already erased node\")\n",
      "/home/mushahid/anaconda3/envs/esp32-env/lib/python3.11/site-packages/torch/fx/graph.py:1157: UserWarning: erase_node(batch_norm_115) on an already erased node\n",
      "  warnings.warn(f\"erase_node({to_erase}) on an already erased node\")\n",
      "/home/mushahid/anaconda3/envs/esp32-env/lib/python3.11/site-packages/torch/fx/graph.py:1157: UserWarning: erase_node(batch_norm_116) on an already erased node\n",
      "  warnings.warn(f\"erase_node({to_erase}) on an already erased node\")\n",
      "/home/mushahid/anaconda3/envs/esp32-env/lib/python3.11/site-packages/torch/fx/graph.py:1157: UserWarning: erase_node(batch_norm_117) on an already erased node\n",
      "  warnings.warn(f\"erase_node({to_erase}) on an already erased node\")\n",
      "/home/mushahid/anaconda3/envs/esp32-env/lib/python3.11/site-packages/torch/fx/graph.py:1157: UserWarning: erase_node(batch_norm_118) on an already erased node\n",
      "  warnings.warn(f\"erase_node({to_erase}) on an already erased node\")\n",
      "/home/mushahid/anaconda3/envs/esp32-env/lib/python3.11/site-packages/torch/fx/graph.py:1157: UserWarning: erase_node(batch_norm_119) on an already erased node\n",
      "  warnings.warn(f\"erase_node({to_erase}) on an already erased node\")\n",
      "/home/mushahid/anaconda3/envs/esp32-env/lib/python3.11/site-packages/torch/fx/graph.py:1157: UserWarning: erase_node(batch_norm_120) on an already erased node\n",
      "  warnings.warn(f\"erase_node({to_erase}) on an already erased node\")\n",
      "/home/mushahid/anaconda3/envs/esp32-env/lib/python3.11/site-packages/torch/fx/graph.py:1157: UserWarning: erase_node(batch_norm_121) on an already erased node\n",
      "  warnings.warn(f\"erase_node({to_erase}) on an already erased node\")\n",
      "/home/mushahid/anaconda3/envs/esp32-env/lib/python3.11/site-packages/torch/fx/graph.py:1157: UserWarning: erase_node(batch_norm_122) on an already erased node\n",
      "  warnings.warn(f\"erase_node({to_erase}) on an already erased node\")\n",
      "/home/mushahid/anaconda3/envs/esp32-env/lib/python3.11/site-packages/torch/fx/graph.py:1157: UserWarning: erase_node(batch_norm_123) on an already erased node\n",
      "  warnings.warn(f\"erase_node({to_erase}) on an already erased node\")\n",
      "/home/mushahid/anaconda3/envs/esp32-env/lib/python3.11/site-packages/torch/fx/graph.py:1157: UserWarning: erase_node(batch_norm_124) on an already erased node\n",
      "  warnings.warn(f\"erase_node({to_erase}) on an already erased node\")\n",
      "/home/mushahid/anaconda3/envs/esp32-env/lib/python3.11/site-packages/torch/fx/graph.py:1157: UserWarning: erase_node(batch_norm_125) on an already erased node\n",
      "  warnings.warn(f\"erase_node({to_erase}) on an already erased node\")\n",
      "/home/mushahid/anaconda3/envs/esp32-env/lib/python3.11/site-packages/torch/fx/graph.py:1157: UserWarning: erase_node(batch_norm_126) on an already erased node\n",
      "  warnings.warn(f\"erase_node({to_erase}) on an already erased node\")\n",
      "/home/mushahid/anaconda3/envs/esp32-env/lib/python3.11/site-packages/torch/fx/graph.py:1157: UserWarning: erase_node(batch_norm_127) on an already erased node\n",
      "  warnings.warn(f\"erase_node({to_erase}) on an already erased node\")\n",
      "/home/mushahid/anaconda3/envs/esp32-env/lib/python3.11/site-packages/torch/fx/graph.py:1157: UserWarning: erase_node(batch_norm_128) on an already erased node\n",
      "  warnings.warn(f\"erase_node({to_erase}) on an already erased node\")\n",
      "/home/mushahid/anaconda3/envs/esp32-env/lib/python3.11/site-packages/torch/fx/graph.py:1157: UserWarning: erase_node(batch_norm_129) on an already erased node\n",
      "  warnings.warn(f\"erase_node({to_erase}) on an already erased node\")\n",
      "/home/mushahid/anaconda3/envs/esp32-env/lib/python3.11/site-packages/torch/fx/graph.py:1157: UserWarning: erase_node(batch_norm_130) on an already erased node\n",
      "  warnings.warn(f\"erase_node({to_erase}) on an already erased node\")\n",
      "/home/mushahid/anaconda3/envs/esp32-env/lib/python3.11/site-packages/torch/fx/graph.py:1157: UserWarning: erase_node(batch_norm_131) on an already erased node\n",
      "  warnings.warn(f\"erase_node({to_erase}) on an already erased node\")\n",
      "/home/mushahid/anaconda3/envs/esp32-env/lib/python3.11/site-packages/torch/fx/graph.py:1157: UserWarning: erase_node(batch_norm_132) on an already erased node\n",
      "  warnings.warn(f\"erase_node({to_erase}) on an already erased node\")\n",
      "/home/mushahid/anaconda3/envs/esp32-env/lib/python3.11/site-packages/torch/fx/graph.py:1157: UserWarning: erase_node(batch_norm_133) on an already erased node\n",
      "  warnings.warn(f\"erase_node({to_erase}) on an already erased node\")\n",
      "/home/mushahid/anaconda3/envs/esp32-env/lib/python3.11/site-packages/torch/fx/graph.py:1157: UserWarning: erase_node(batch_norm_134) on an already erased node\n",
      "  warnings.warn(f\"erase_node({to_erase}) on an already erased node\")\n",
      "/home/mushahid/anaconda3/envs/esp32-env/lib/python3.11/site-packages/torch/fx/graph.py:1157: UserWarning: erase_node(batch_norm_135) on an already erased node\n",
      "  warnings.warn(f\"erase_node({to_erase}) on an already erased node\")\n",
      "/home/mushahid/anaconda3/envs/esp32-env/lib/python3.11/site-packages/torch/fx/graph.py:1157: UserWarning: erase_node(batch_norm_136) on an already erased node\n",
      "  warnings.warn(f\"erase_node({to_erase}) on an already erased node\")\n",
      "/home/mushahid/anaconda3/envs/esp32-env/lib/python3.11/site-packages/torch/fx/graph.py:1157: UserWarning: erase_node(batch_norm_137) on an already erased node\n",
      "  warnings.warn(f\"erase_node({to_erase}) on an already erased node\")\n",
      "/home/mushahid/anaconda3/envs/esp32-env/lib/python3.11/site-packages/torch/fx/graph.py:1157: UserWarning: erase_node(batch_norm_138) on an already erased node\n",
      "  warnings.warn(f\"erase_node({to_erase}) on an already erased node\")\n",
      "/home/mushahid/anaconda3/envs/esp32-env/lib/python3.11/site-packages/torch/fx/graph.py:1157: UserWarning: erase_node(batch_norm_139) on an already erased node\n",
      "  warnings.warn(f\"erase_node({to_erase}) on an already erased node\")\n",
      "/home/mushahid/anaconda3/envs/esp32-env/lib/python3.11/site-packages/torch/fx/graph.py:1157: UserWarning: erase_node(batch_norm_140) on an already erased node\n",
      "  warnings.warn(f\"erase_node({to_erase}) on an already erased node\")\n",
      "/home/mushahid/anaconda3/envs/esp32-env/lib/python3.11/site-packages/torch/fx/graph.py:1157: UserWarning: erase_node(batch_norm_141) on an already erased node\n",
      "  warnings.warn(f\"erase_node({to_erase}) on an already erased node\")\n",
      "/home/mushahid/anaconda3/envs/esp32-env/lib/python3.11/site-packages/torch/fx/graph.py:1157: UserWarning: erase_node(batch_norm_142) on an already erased node\n",
      "  warnings.warn(f\"erase_node({to_erase}) on an already erased node\")\n",
      "/home/mushahid/anaconda3/envs/esp32-env/lib/python3.11/site-packages/torch/fx/graph.py:1157: UserWarning: erase_node(batch_norm_143) on an already erased node\n",
      "  warnings.warn(f\"erase_node({to_erase}) on an already erased node\")\n",
      "/home/mushahid/anaconda3/envs/esp32-env/lib/python3.11/site-packages/torch/fx/graph.py:1157: UserWarning: erase_node(batch_norm_144) on an already erased node\n",
      "  warnings.warn(f\"erase_node({to_erase}) on an already erased node\")\n",
      "/home/mushahid/anaconda3/envs/esp32-env/lib/python3.11/site-packages/torch/fx/graph.py:1157: UserWarning: erase_node(batch_norm_145) on an already erased node\n",
      "  warnings.warn(f\"erase_node({to_erase}) on an already erased node\")\n",
      "/home/mushahid/anaconda3/envs/esp32-env/lib/python3.11/site-packages/torch/fx/graph.py:1157: UserWarning: erase_node(batch_norm_146) on an already erased node\n",
      "  warnings.warn(f\"erase_node({to_erase}) on an already erased node\")\n"
     ]
    }
   ],
   "source": [
    "from executorch.exir import to_edge_transform_and_lower\n",
    "from executorch.backends.xnnpack.partition.xnnpack_partitioner import XnnpackPartitioner\n",
    "\n",
    "from torchao.quantization.pt2e.quantize_pt2e import (\n",
    "  convert_pt2e,\n",
    ")\n",
    "\n",
    "quantized_model = convert_pt2e(prepared_model)\n",
    "\n",
    "sample_inputs = (torch.randn(2, 1, 224, 224),)\n",
    "\n",
    "et_program = to_edge_transform_and_lower( # (6)\n",
    "    torch.export.export(quantized_model, sample_inputs),\n",
    "    partitioner=[XnnpackPartitioner()],\n",
    ").to_executorch()\n",
    "\n",
    "# 3. Save for deployment\n",
    "with open(\"model.pte\", \"wb\") as f:\n",
    "    f.write(et_program.buffer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a4129e3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "esp32-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
