{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "50062854",
   "metadata": {},
   "outputs": [],
   "source": [
    "config = {\n",
    "    \"use_aug\" : False,\n",
    "    \"num_classes\" : 264,\n",
    "    \"batch_size\" : 64,\n",
    "    \"epochs\" : 1,\n",
    "    \"PRECISION\" : 16,\n",
    "    \"PATIENCE\" : 8,    \n",
    "    \"seed\" : 64,\n",
    "    \"model\" : \"tf_efficientnet_b1_ns\",\n",
    "    \"pretrained\" : True,            \n",
    "    \"weight_decay\" : 1e-3,\n",
    "    \"use_mixup\" : True,\n",
    "    \"mixup_alpha\" : 0.6,  \n",
    "\n",
    "    \"train_images\" : \"/mnt/Stuff/phd_projects/esp32-projects/bird_call_id/splitted_dataset_color/train\",\n",
    "    \"valid_images\" : \"/mnt/Stuff/phd_projects/esp32-projects/bird_call_id/splitted_dataset_color/test\",\n",
    "    \n",
    "    \"SR\" : 32000,\n",
    "    \"DURATION\" : 5,\n",
    "    \"MAX_READ_SAMPLES\" : 5,\n",
    "    \"LR\" : 1e-3\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "547266a1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-10-20 00:27:48.176294: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2025-10-20 00:27:48.213047: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2025-10-20 00:27:49.049944: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "EFFICIENTNETB0 TRAINING PIPELINE\n",
      "============================================================\n",
      "\n",
      "1. Loading datasets...\n",
      "Found 10860 images belonging to 264 classes.\n",
      "Found 2585 images belonging to 264 classes.\n",
      "Found 3496 images belonging to 264 classes.\n",
      "Number of classes: 264\n",
      "\n",
      "2. Building model...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "I0000 00:00:1760898470.487851   88091 gpu_device.cc:2020] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 9648 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 3060, pci bus id: 0000:01:00.0, compute capability: 8.6\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:The following Variables were used in a Lambda layer's call (tf.nn.bias_add), but are not present in its tracked objects:   <tf.Variable 'dense/bias:0' shape=(256,) dtype=float32>. This is a strong indication that the Lambda layer should be rewritten as a subclassed Layer.\n",
      "WARNING:tensorflow:The following Variables were used in a Lambda layer's call (tf.nn.bias_add_1), but are not present in its tracked objects:   <tf.Variable 'dense_1/bias:0' shape=(264,) dtype=float32>. This is a strong indication that the Lambda layer should be rewritten as a subclassed Layer.\n",
      "Total parameters: 4,049,571\n",
      "\n",
      "3. Initial training...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E0000 00:00:1760898479.196422   88091 meta_optimizer.cc:967] layout failed: INVALID_ARGUMENT: Size of values 0 does not match size of permutation 4 @ fanin shape inmodel/block2b_drop/dropout/SelectV2-2-TransposeNHWCToNCHW-LayoutOptimizer\n",
      "2025-10-20 00:28:00.656288: I external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:473] Loaded cuDNN version 91002\n",
      "2025-10-20 00:28:01.381926: I external/local_xla/xla/service/service.cc:163] XLA service 0x703485128c70 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
      "2025-10-20 00:28:01.381938: I external/local_xla/xla/service/service.cc:171]   StreamExecutor device (0): NVIDIA GeForce RTX 3060, Compute Capability 8.6\n",
      "2025-10-20 00:28:01.386269: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:269] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\n",
      "I0000 00:00:1760898481.434005   88200 device_compiler.h:196] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "340/340 [==============================] - 175s 461ms/step - loss: 4.8904 - accuracy: 0.1207 - top3_acc: 0.2111 - val_loss: 5.5567 - val_accuracy: 0.0232 - val_top3_acc: 0.0476 - lr: 0.0010\n",
      "\n",
      "5. Applying pruning...\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Please initialize `Prune` with a supported layer. Layers should either be supported by the PruneRegistry (built-in keras layers) or should be a `PrunableLayer` instance, or should has a customer defined `get_prunable_weights` method. You passed: <class 'tf_keras.src.layers.preprocessing.image_preprocessing.Rescaling'>",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mValueError\u001b[39m                                Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[1]\u001b[39m\u001b[32m, line 406\u001b[39m\n\u001b[32m    403\u001b[39m     \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33mPlease install: pip install tensorflow-model-optimization\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m    404\u001b[39m     exit(\u001b[32m1\u001b[39m)\n\u001b[32m--> \u001b[39m\u001b[32m406\u001b[39m \u001b[43mmain\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[1]\u001b[39m\u001b[32m, line 361\u001b[39m, in \u001b[36mmain\u001b[39m\u001b[34m()\u001b[39m\n\u001b[32m    355\u001b[39m \u001b[38;5;66;03m# Evaluate base model\u001b[39;00m\n\u001b[32m    356\u001b[39m \u001b[38;5;66;03m# print(\"\\n4. Evaluating base model...\")\u001b[39;00m\n\u001b[32m    357\u001b[39m \u001b[38;5;66;03m# evaluate_model(model, test_ds)\u001b[39;00m\n\u001b[32m    358\u001b[39m \n\u001b[32m    359\u001b[39m \u001b[38;5;66;03m# Apply pruning\u001b[39;00m\n\u001b[32m    360\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m5. Applying pruning...\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m--> \u001b[39m\u001b[32m361\u001b[39m model_pruned, prune_history = \u001b[43mapply_pruning\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_ds\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mval_ds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    362\u001b[39m evaluate_model(model_pruned, test_ds)\n\u001b[32m    364\u001b[39m \u001b[38;5;66;03m# Save pruned model\u001b[39;00m\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[1]\u001b[39m\u001b[32m, line 152\u001b[39m, in \u001b[36mapply_pruning\u001b[39m\u001b[34m(model, train_ds, val_ds, epochs)\u001b[39m\n\u001b[32m    142\u001b[39m pruning_params = {\n\u001b[32m    143\u001b[39m     \u001b[33m'\u001b[39m\u001b[33mpruning_schedule\u001b[39m\u001b[33m'\u001b[39m: tfmot.sparsity.keras.PolynomialDecay(\n\u001b[32m    144\u001b[39m         initial_sparsity=\u001b[32m0.0\u001b[39m,\n\u001b[32m   (...)\u001b[39m\u001b[32m    148\u001b[39m     )\n\u001b[32m    149\u001b[39m }\n\u001b[32m    151\u001b[39m \u001b[38;5;66;03m# Apply pruning to model\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m152\u001b[39m model_for_pruning = \u001b[43mprune_low_magnitude\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mpruning_params\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    154\u001b[39m model_for_pruning.compile(\n\u001b[32m    155\u001b[39m     optimizer=keras.optimizers.Adam(learning_rate=LEARNING_RATE * \u001b[32m0.1\u001b[39m),\n\u001b[32m    156\u001b[39m     loss=\u001b[33m'\u001b[39m\u001b[33mcategorical_crossentropy\u001b[39m\u001b[33m'\u001b[39m,\n\u001b[32m    157\u001b[39m     metrics=[\u001b[33m'\u001b[39m\u001b[33maccuracy\u001b[39m\u001b[33m'\u001b[39m, keras.metrics.TopKCategoricalAccuracy(k=\u001b[32m3\u001b[39m, name=\u001b[33m'\u001b[39m\u001b[33mtop3_acc\u001b[39m\u001b[33m'\u001b[39m)]\n\u001b[32m    158\u001b[39m )\n\u001b[32m    160\u001b[39m callbacks = [\n\u001b[32m    161\u001b[39m     tfmot.sparsity.keras.UpdatePruningStep(),\n\u001b[32m    162\u001b[39m     keras.callbacks.EarlyStopping(\n\u001b[32m   (...)\u001b[39m\u001b[32m    166\u001b[39m     )\n\u001b[32m    167\u001b[39m ]\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/anaconda3/envs/tf-env-esp32/lib/python3.11/site-packages/tensorflow_model_optimization/python/core/keras/metrics.py:74\u001b[39m, in \u001b[36mMonitorBoolGauge.__call__.<locals>.inner\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m     72\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m error:\n\u001b[32m     73\u001b[39m   \u001b[38;5;28mself\u001b[39m.bool_gauge.get_cell(MonitorBoolGauge._FAILURE_LABEL).set(\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[32m---> \u001b[39m\u001b[32m74\u001b[39m   \u001b[38;5;28;01mraise\u001b[39;00m error\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/anaconda3/envs/tf-env-esp32/lib/python3.11/site-packages/tensorflow_model_optimization/python/core/keras/metrics.py:69\u001b[39m, in \u001b[36mMonitorBoolGauge.__call__.<locals>.inner\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m     66\u001b[39m \u001b[38;5;129m@functools\u001b[39m.wraps(func)\n\u001b[32m     67\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34minner\u001b[39m(*args, **kwargs):\n\u001b[32m     68\u001b[39m   \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m---> \u001b[39m\u001b[32m69\u001b[39m     results = \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     70\u001b[39m     \u001b[38;5;28mself\u001b[39m.bool_gauge.get_cell(MonitorBoolGauge._SUCCESS_LABEL).set(\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[32m     71\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m results\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/anaconda3/envs/tf-env-esp32/lib/python3.11/site-packages/tensorflow_model_optimization/python/core/sparsity/keras/prune.py:211\u001b[39m, in \u001b[36mprune_low_magnitude\u001b[39m\u001b[34m(to_prune, pruning_schedule, block_size, block_pooling_type, pruning_policy, sparsity_m_by_n, **kwargs)\u001b[39m\n\u001b[32m    209\u001b[39m   \u001b[38;5;28;01mif\u001b[39;00m pruning_policy:\n\u001b[32m    210\u001b[39m     pruning_policy.ensure_model_supports_pruning(to_prune)\n\u001b[32m--> \u001b[39m\u001b[32m211\u001b[39m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_add_pruning_wrapper\u001b[49m\u001b[43m(\u001b[49m\u001b[43mto_prune\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    212\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m is_keras_layer:\n\u001b[32m    213\u001b[39m   params.update(kwargs)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/anaconda3/envs/tf-env-esp32/lib/python3.11/site-packages/tensorflow_model_optimization/python/core/sparsity/keras/prune.py:182\u001b[39m, in \u001b[36mprune_low_magnitude.<locals>._add_pruning_wrapper\u001b[39m\u001b[34m(layer)\u001b[39m\n\u001b[32m    178\u001b[39m   \u001b[38;5;28;01mif\u001b[39;00m (\u001b[38;5;129;01mnot\u001b[39;00m layer._is_graph_network \u001b[38;5;129;01mand\u001b[39;00m\n\u001b[32m    179\u001b[39m       \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(layer, keras.models.Sequential)):\n\u001b[32m    180\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[33m'\u001b[39m\u001b[33mSubclassed models are not supported currently.\u001b[39m\u001b[33m'\u001b[39m)\n\u001b[32m--> \u001b[39m\u001b[32m182\u001b[39m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mkeras\u001b[49m\u001b[43m.\u001b[49m\u001b[43mmodels\u001b[49m\u001b[43m.\u001b[49m\u001b[43mclone_model\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    183\u001b[39m \u001b[43m      \u001b[49m\u001b[43mlayer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minput_tensors\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mclone_function\u001b[49m\u001b[43m=\u001b[49m\u001b[43m_add_pruning_wrapper\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    184\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(layer, pruning_wrapper.PruneLowMagnitude):\n\u001b[32m    185\u001b[39m   \u001b[38;5;28;01mreturn\u001b[39;00m layer\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/anaconda3/envs/tf-env-esp32/lib/python3.11/site-packages/tf_keras/src/models/cloning.py:540\u001b[39m, in \u001b[36mclone_model\u001b[39m\u001b[34m(model, input_tensors, clone_function)\u001b[39m\n\u001b[32m    530\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(model, functional.Functional):\n\u001b[32m    531\u001b[39m     \u001b[38;5;66;03m# If the get_config() method is the same as a regular Functional\u001b[39;00m\n\u001b[32m    532\u001b[39m     \u001b[38;5;66;03m# model, we're safe to use _clone_functional_model (which relies\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m    535\u001b[39m     \u001b[38;5;66;03m# or input_tensors are passed, we attempt it anyway\u001b[39;00m\n\u001b[32m    536\u001b[39m     \u001b[38;5;66;03m# in order to preserve backwards compatibility.\u001b[39;00m\n\u001b[32m    537\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m generic_utils.is_default(model.get_config) \u001b[38;5;129;01mor\u001b[39;00m (\n\u001b[32m    538\u001b[39m         clone_function \u001b[38;5;129;01mor\u001b[39;00m input_tensors\n\u001b[32m    539\u001b[39m     ):\n\u001b[32m--> \u001b[39m\u001b[32m540\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_clone_functional_model\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    541\u001b[39m \u001b[43m            \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minput_tensors\u001b[49m\u001b[43m=\u001b[49m\u001b[43minput_tensors\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlayer_fn\u001b[49m\u001b[43m=\u001b[49m\u001b[43mclone_function\u001b[49m\n\u001b[32m    542\u001b[39m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    544\u001b[39m \u001b[38;5;66;03m# Case of a custom model class\u001b[39;00m\n\u001b[32m    545\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m clone_function \u001b[38;5;129;01mor\u001b[39;00m input_tensors:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/anaconda3/envs/tf-env-esp32/lib/python3.11/site-packages/tf_keras/src/models/cloning.py:222\u001b[39m, in \u001b[36m_clone_functional_model\u001b[39m\u001b[34m(model, input_tensors, layer_fn)\u001b[39m\n\u001b[32m    218\u001b[39m         model_configs, created_layers = _clone_layers_and_model_config(\n\u001b[32m    219\u001b[39m             model, new_input_layers, layer_fn\n\u001b[32m    220\u001b[39m         )\n\u001b[32m    221\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m222\u001b[39m     model_configs, created_layers = \u001b[43m_clone_layers_and_model_config\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    223\u001b[39m \u001b[43m        \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnew_input_layers\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlayer_fn\u001b[49m\n\u001b[32m    224\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    225\u001b[39m \u001b[38;5;66;03m# Reconstruct model from the config, using the cloned layers.\u001b[39;00m\n\u001b[32m    226\u001b[39m (\n\u001b[32m    227\u001b[39m     input_tensors,\n\u001b[32m    228\u001b[39m     output_tensors,\n\u001b[32m   (...)\u001b[39m\u001b[32m    231\u001b[39m     model_configs, created_layers=created_layers\n\u001b[32m    232\u001b[39m )\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/anaconda3/envs/tf-env-esp32/lib/python3.11/site-packages/tf_keras/src/models/cloning.py:298\u001b[39m, in \u001b[36m_clone_layers_and_model_config\u001b[39m\u001b[34m(model, input_layers, layer_fn)\u001b[39m\n\u001b[32m    295\u001b[39m         created_layers[layer.name] = layer_fn(layer)\n\u001b[32m    296\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m {}\n\u001b[32m--> \u001b[39m\u001b[32m298\u001b[39m config = \u001b[43mfunctional\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget_network_config\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    299\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mserialize_layer_fn\u001b[49m\u001b[43m=\u001b[49m\u001b[43m_copy_layer\u001b[49m\n\u001b[32m    300\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    301\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m config, created_layers\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/anaconda3/envs/tf-env-esp32/lib/python3.11/site-packages/tf_keras/src/engine/functional.py:1592\u001b[39m, in \u001b[36mget_network_config\u001b[39m\u001b[34m(network, serialize_layer_fn, config)\u001b[39m\n\u001b[32m   1590\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(layer, Functional) \u001b[38;5;129;01mand\u001b[39;00m set_layers_legacy:\n\u001b[32m   1591\u001b[39m     layer.use_legacy_config = \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m1592\u001b[39m layer_config = \u001b[43mserialize_layer_fn\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlayer\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1593\u001b[39m layer_config[\u001b[33m\"\u001b[39m\u001b[33mname\u001b[39m\u001b[33m\"\u001b[39m] = layer.name\n\u001b[32m   1594\u001b[39m layer_config[\u001b[33m\"\u001b[39m\u001b[33minbound_nodes\u001b[39m\u001b[33m\"\u001b[39m] = filtered_inbound_nodes\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/anaconda3/envs/tf-env-esp32/lib/python3.11/site-packages/tf_keras/src/models/cloning.py:295\u001b[39m, in \u001b[36m_clone_layers_and_model_config.<locals>._copy_layer\u001b[39m\u001b[34m(layer)\u001b[39m\n\u001b[32m    293\u001b[39m     created_layers[layer.name] = InputLayer(**layer.get_config())\n\u001b[32m    294\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m295\u001b[39m     created_layers[layer.name] = \u001b[43mlayer_fn\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlayer\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    296\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m {}\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/anaconda3/envs/tf-env-esp32/lib/python3.11/site-packages/tensorflow_model_optimization/python/core/sparsity/keras/prune.py:189\u001b[39m, in \u001b[36mprune_low_magnitude.<locals>._add_pruning_wrapper\u001b[39m\u001b[34m(layer)\u001b[39m\n\u001b[32m    187\u001b[39m   \u001b[38;5;28;01mreturn\u001b[39;00m layer\n\u001b[32m    188\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m189\u001b[39m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mpruning_wrapper\u001b[49m\u001b[43m.\u001b[49m\u001b[43mPruneLowMagnitude\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlayer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mparams\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/anaconda3/envs/tf-env-esp32/lib/python3.11/site-packages/tensorflow_model_optimization/python/core/sparsity/keras/pruning_wrapper.py:191\u001b[39m, in \u001b[36mPruneLowMagnitude.__init__\u001b[39m\u001b[34m(self, layer, pruning_schedule, block_size, block_pooling_type, sparsity_m_by_n, **kwargs)\u001b[39m\n\u001b[32m    188\u001b[39m   \u001b[38;5;28msuper\u001b[39m(PruneLowMagnitude, \u001b[38;5;28mself\u001b[39m).\u001b[34m__init__\u001b[39m(\n\u001b[32m    189\u001b[39m       prune_registry.PruneRegistry.make_prunable(layer), **kwargs)\n\u001b[32m    190\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m191\u001b[39m   \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[32m    192\u001b[39m       \u001b[33m'\u001b[39m\u001b[33mPlease initialize `Prune` with a supported layer. Layers should \u001b[39m\u001b[33m'\u001b[39m\n\u001b[32m    193\u001b[39m       \u001b[33m'\u001b[39m\u001b[33meither be supported by the PruneRegistry (built-in keras layers) or \u001b[39m\u001b[33m'\u001b[39m\n\u001b[32m    194\u001b[39m       \u001b[33m'\u001b[39m\u001b[33mshould be a `PrunableLayer` instance, or should has a customer \u001b[39m\u001b[33m'\u001b[39m\n\u001b[32m    195\u001b[39m       \u001b[33m'\u001b[39m\u001b[33mdefined `get_prunable_weights` method. You passed: \u001b[39m\u001b[33m'\u001b[39m\n\u001b[32m    196\u001b[39m       \u001b[33m'\u001b[39m\u001b[38;5;132;01m{input}\u001b[39;00m\u001b[33m'\u001b[39m.format(\u001b[38;5;28minput\u001b[39m=layer.\u001b[34m__class__\u001b[39m))\n\u001b[32m    198\u001b[39m \u001b[38;5;28mself\u001b[39m._track_trackable(layer, name=\u001b[33m'\u001b[39m\u001b[33mlayer\u001b[39m\u001b[33m'\u001b[39m)\n\u001b[32m    200\u001b[39m \u001b[38;5;66;03m# TODO(yunluli): Work-around to handle the first layer of Sequential model\u001b[39;00m\n\u001b[32m    201\u001b[39m \u001b[38;5;66;03m# properly. Can remove this when it is implemented in the Wrapper base\u001b[39;00m\n\u001b[32m    202\u001b[39m \u001b[38;5;66;03m# class.\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m    219\u001b[39m \u001b[38;5;66;03m# built. Being not built is confusing since the end-user has passed an\u001b[39;00m\n\u001b[32m    220\u001b[39m \u001b[38;5;66;03m# input shape.\u001b[39;00m\n",
      "\u001b[31mValueError\u001b[39m: Please initialize `Prune` with a supported layer. Layers should either be supported by the PruneRegistry (built-in keras layers) or should be a `PrunableLayer` instance, or should has a customer defined `get_prunable_weights` method. You passed: <class 'tf_keras.src.layers.preprocessing.image_preprocessing.Rescaling'>"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "import tensorflow_model_optimization as tfmot\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "# Configuration\n",
    "IMG_SIZE = 224\n",
    "BATCH_SIZE = 32\n",
    "EPOCHS = 1\n",
    "FINE_TUNE_EPOCHS = 30\n",
    "QAT_EPOCHS = 1\n",
    "LEARNING_RATE = 0.001\n",
    "DATA_DIR = '/mnt/Stuff/phd_projects/esp32-projects/bird_call_id/splitted_dataset_color'  # Update this path\n",
    "\n",
    "# 1. DATA LOADING\n",
    "def create_datasets(data_dir, img_size=IMG_SIZE, batch_size=BATCH_SIZE):\n",
    "    \"\"\"Load and prepare train/test datasets\"\"\"\n",
    "    train_dir = os.path.join(data_dir, 'train')\n",
    "    test_dir = os.path.join(data_dir, 'test')\n",
    "    \n",
    "    # Data augmentation for training\n",
    "    train_datagen = keras.preprocessing.image.ImageDataGenerator(\n",
    "        rescale=1./255,\n",
    "        rotation_range=20,\n",
    "        width_shift_range=0.2,\n",
    "        height_shift_range=0.2,\n",
    "        horizontal_flip=True,\n",
    "        zoom_range=0.2,\n",
    "        shear_range=0.2,\n",
    "        fill_mode='nearest',\n",
    "        validation_split=0.2  # 20% for validation\n",
    "    )\n",
    "    \n",
    "    test_datagen = keras.preprocessing.image.ImageDataGenerator(\n",
    "        rescale=1./255\n",
    "    )\n",
    "    \n",
    "    train_ds = train_datagen.flow_from_directory(\n",
    "        train_dir,\n",
    "        target_size=(img_size, img_size),\n",
    "        batch_size=batch_size,\n",
    "        class_mode='categorical',\n",
    "        subset='training',\n",
    "        shuffle=True\n",
    "    )\n",
    "    \n",
    "    val_ds = train_datagen.flow_from_directory(\n",
    "        train_dir,\n",
    "        target_size=(img_size, img_size),\n",
    "        batch_size=batch_size,\n",
    "        class_mode='categorical',\n",
    "        subset='validation',\n",
    "        shuffle=False\n",
    "    )\n",
    "    \n",
    "    test_ds = test_datagen.flow_from_directory(\n",
    "        test_dir,\n",
    "        target_size=(img_size, img_size),\n",
    "        batch_size=batch_size,\n",
    "        class_mode='categorical',\n",
    "        shuffle=False\n",
    "    )\n",
    "    \n",
    "    num_classes = len(train_ds.class_indices)\n",
    "    \n",
    "    return train_ds, val_ds, test_ds, num_classes\n",
    "\n",
    "\n",
    "# 2. MODEL BUILDING\n",
    "def build_model(num_classes, img_size=IMG_SIZE):\n",
    "    \"\"\"Build EfficientNetB0 model with custom head\"\"\"\n",
    "    inputs = keras.Input(shape=(img_size, img_size, 3))\n",
    "    \n",
    "    # Load EfficientNetB0 backbone (trainable)\n",
    "    backbone = keras.applications.EfficientNetB0(\n",
    "        include_top=False,\n",
    "        weights='imagenet',\n",
    "        input_tensor=inputs,\n",
    "        pooling='avg'\n",
    "    )\n",
    "    backbone.trainable = True  # Backbone is NOT frozen\n",
    "    \n",
    "    x = backbone.output\n",
    "    x = layers.Dropout(0.3)(x)\n",
    "    x = layers.Dense(256, activation='relu')(x)\n",
    "    x = layers.Dropout(0.2)(x)\n",
    "    outputs = layers.Dense(num_classes, activation='softmax')(x)\n",
    "    \n",
    "    model = keras.Model(inputs=inputs, outputs=outputs)\n",
    "    \n",
    "    return model\n",
    "\n",
    "\n",
    "# 3. INITIAL TRAINING\n",
    "def train_model(model, train_ds, val_ds, epochs=EPOCHS, lr=LEARNING_RATE):\n",
    "    \"\"\"Initial training phase\"\"\"\n",
    "    model.compile(\n",
    "        optimizer=keras.optimizers.Adam(learning_rate=lr),\n",
    "        loss='categorical_crossentropy',\n",
    "        metrics=['accuracy', keras.metrics.TopKCategoricalAccuracy(k=3, name='top3_acc')]\n",
    "    )\n",
    "    \n",
    "    callbacks = [\n",
    "        keras.callbacks.EarlyStopping(\n",
    "            monitor='val_loss',\n",
    "            patience=10,\n",
    "            restore_best_weights=True\n",
    "        ),\n",
    "        keras.callbacks.ReduceLROnPlateau(\n",
    "            monitor='val_loss',\n",
    "            factor=0.5,\n",
    "            patience=5,\n",
    "            min_lr=1e-7\n",
    "        ),\n",
    "        # keras.callbacks.ModelCheckpoint(\n",
    "        #     'best_model',\n",
    "        #     monitor='val_accuracy',\n",
    "        #     save_best_only=True,\n",
    "        #     mode='max',\n",
    "        #     save_format='tf'  # Use SavedModel format\n",
    "        # )\n",
    "    ]\n",
    "    \n",
    "    history = model.fit(\n",
    "        train_ds,\n",
    "        validation_data=val_ds,\n",
    "        epochs=epochs,\n",
    "        callbacks=callbacks\n",
    "    )\n",
    "    \n",
    "    return history\n",
    "\n",
    "\n",
    "# 4. PRUNING\n",
    "def apply_pruning(model, train_ds, val_ds, epochs=FINE_TUNE_EPOCHS):\n",
    "    \"\"\"Apply magnitude-based pruning\"\"\"\n",
    "    prune_low_magnitude = tfmot.sparsity.keras.prune_low_magnitude\n",
    "    \n",
    "    # Pruning configuration\n",
    "    pruning_params = {\n",
    "        'pruning_schedule': tfmot.sparsity.keras.PolynomialDecay(\n",
    "            initial_sparsity=0.0,\n",
    "            final_sparsity=0.5,\n",
    "            begin_step=0,\n",
    "            end_step=len(train_ds) * epochs\n",
    "        )\n",
    "    }\n",
    "    \n",
    "    # Apply pruning to model\n",
    "    model_for_pruning = prune_low_magnitude(model, **pruning_params)\n",
    "    \n",
    "    model_for_pruning.compile(\n",
    "        optimizer=keras.optimizers.Adam(learning_rate=LEARNING_RATE * 0.1),\n",
    "        loss='categorical_crossentropy',\n",
    "        metrics=['accuracy', keras.metrics.TopKCategoricalAccuracy(k=3, name='top3_acc')]\n",
    "    )\n",
    "    \n",
    "    callbacks = [\n",
    "        tfmot.sparsity.keras.UpdatePruningStep(),\n",
    "        keras.callbacks.EarlyStopping(\n",
    "            monitor='val_loss',\n",
    "            patience=5,\n",
    "            restore_best_weights=True\n",
    "        )\n",
    "    ]\n",
    "    \n",
    "    print(\"\\n\" + \"=\"*50)\n",
    "    print(\"PRUNING PHASE\")\n",
    "    print(\"=\"*50)\n",
    "    \n",
    "    history = model_for_pruning.fit(\n",
    "        train_ds,\n",
    "        validation_data=val_ds,\n",
    "        epochs=epochs,\n",
    "        callbacks=callbacks\n",
    "    )\n",
    "    \n",
    "    # Strip pruning wrappers\n",
    "    model_pruned = tfmot.sparsity.keras.strip_pruning(model_for_pruning)\n",
    "    \n",
    "    return model_pruned, history\n",
    "\n",
    "\n",
    "# 5. QUANTIZATION AWARE TRAINING (QAT)\n",
    "def apply_qat(model, train_ds, val_ds, epochs=QAT_EPOCHS):\n",
    "    \"\"\"Apply Quantization Aware Training\"\"\"\n",
    "    quantize_model = tfmot.quantization.keras.quantize_model\n",
    "    \n",
    "    # Apply QAT\n",
    "    q_aware_model = quantize_model(model)\n",
    "    \n",
    "    q_aware_model.compile(\n",
    "        optimizer=keras.optimizers.Adam(learning_rate=LEARNING_RATE * 0.01),\n",
    "        loss='categorical_crossentropy',\n",
    "        metrics=['accuracy', keras.metrics.TopKCategoricalAccuracy(k=3, name='top3_acc')]\n",
    "    )\n",
    "    \n",
    "    callbacks = [\n",
    "        keras.callbacks.EarlyStopping(\n",
    "            monitor='val_loss',\n",
    "            patience=5,\n",
    "            restore_best_weights=True\n",
    "        )\n",
    "    ]\n",
    "    \n",
    "    print(\"\\n\" + \"=\"*50)\n",
    "    print(\"QUANTIZATION AWARE TRAINING PHASE\")\n",
    "    print(\"=\"*50)\n",
    "    \n",
    "    history = q_aware_model.fit(\n",
    "        train_ds,\n",
    "        validation_data=val_ds,\n",
    "        epochs=epochs,\n",
    "        callbacks=callbacks\n",
    "    )\n",
    "    \n",
    "    return q_aware_model, history\n",
    "\n",
    "\n",
    "# 6. TFLITE CONVERSION\n",
    "def convert_to_tflite(model, representative_dataset=None, quantize=True):\n",
    "    \"\"\"Convert model to TFLite format\"\"\"\n",
    "    # For QAT models, we need to convert directly without saving first\n",
    "    converter = tf.lite.TFLiteConverter.from_keras_model(model)\n",
    "    \n",
    "    if quantize:\n",
    "        # Full integer quantization\n",
    "        converter.optimizations = [tf.lite.Optimize.DEFAULT]\n",
    "        \n",
    "        if representative_dataset is not None:\n",
    "            converter.representative_dataset = representative_dataset\n",
    "            converter.target_spec.supported_ops = [tf.lite.OpsSet.TFLITE_BUILTINS_INT8]\n",
    "            converter.inference_input_type = tf.uint8\n",
    "            converter.inference_output_type = tf.uint8\n",
    "    \n",
    "    tflite_model = converter.convert()\n",
    "    \n",
    "    return tflite_model\n",
    "\n",
    "\n",
    "def save_qat_model(model, path):\n",
    "    \"\"\"Save QAT model properly by converting to concrete function\"\"\"\n",
    "    try:\n",
    "        # Try direct save first\n",
    "        model.save(path, save_format='tf')\n",
    "        print(f\"Model saved successfully to {path}/\")\n",
    "    except Exception as e:\n",
    "        print(f\"Direct save failed: {e}\")\n",
    "        print(\"Attempting alternative save method...\")\n",
    "        \n",
    "        # Alternative: Clone the model to a standard Keras model\n",
    "        try:\n",
    "            # Get model config and weights\n",
    "            config = model.get_config()\n",
    "            weights = model.get_weights()\n",
    "            \n",
    "            # Create new model from config\n",
    "            new_model = keras.Model.from_config(config)\n",
    "            new_model.set_weights(weights)\n",
    "            \n",
    "            # Save the cloned model\n",
    "            new_model.save(path, save_format='tf')\n",
    "            print(f\"Model saved successfully using cloning method to {path}/\")\n",
    "        except Exception as e2:\n",
    "            print(f\"Cloning save also failed: {e2}\")\n",
    "            print(\"Model will only be saved as TFLite format\")\n",
    "\n",
    "\n",
    "def representative_data_gen(dataset, num_samples=100):\n",
    "    \"\"\"Generate representative dataset for quantization\"\"\"\n",
    "    def gen():\n",
    "        for i, (images, _) in enumerate(dataset):\n",
    "            if i >= num_samples // BATCH_SIZE:\n",
    "                break\n",
    "            for img in images:\n",
    "                yield [np.expand_dims(img, axis=0).astype(np.float32)]\n",
    "    return gen\n",
    "\n",
    "\n",
    "# 7. EVALUATION\n",
    "def evaluate_model(model, test_ds):\n",
    "    \"\"\"Evaluate model performance\"\"\"\n",
    "    results = model.evaluate(test_ds)\n",
    "    print(f\"\\nTest Loss: {results[0]:.4f}\")\n",
    "    print(f\"Test Accuracy: {results[1]:.4f}\")\n",
    "    print(f\"Test Top-3 Accuracy: {results[2]:.4f}\")\n",
    "    return results\n",
    "\n",
    "\n",
    "def evaluate_tflite(tflite_model, test_ds, num_samples=500):\n",
    "    \"\"\"Evaluate TFLite model\"\"\"\n",
    "    interpreter = tf.lite.Interpreter(model_content=tflite_model)\n",
    "    interpreter.allocate_tensors()\n",
    "    \n",
    "    input_details = interpreter.get_input_details()\n",
    "    output_details = interpreter.get_output_details()\n",
    "    \n",
    "    correct = 0\n",
    "    total = 0\n",
    "    \n",
    "    for images, labels in test_ds:\n",
    "        if total >= num_samples:\n",
    "            break\n",
    "            \n",
    "        for i in range(len(images)):\n",
    "            img = np.expand_dims(images[i], axis=0)\n",
    "            \n",
    "            # Adjust input type\n",
    "            if input_details[0]['dtype'] == np.uint8:\n",
    "                img = (img * 255).astype(np.uint8)\n",
    "            else:\n",
    "                img = img.astype(np.float32)\n",
    "            \n",
    "            interpreter.set_tensor(input_details[0]['index'], img)\n",
    "            interpreter.invoke()\n",
    "            predictions = interpreter.get_tensor(output_details[0]['index'])\n",
    "            \n",
    "            pred_class = np.argmax(predictions[0])\n",
    "            true_class = np.argmax(labels[i])\n",
    "            \n",
    "            if pred_class == true_class:\n",
    "                correct += 1\n",
    "            total += 1\n",
    "            \n",
    "            if total >= num_samples:\n",
    "                break\n",
    "    \n",
    "    accuracy = correct / total\n",
    "    print(f\"\\nTFLite Model Accuracy: {accuracy:.4f}\")\n",
    "    return accuracy\n",
    "\n",
    "\n",
    "# 8. MAIN PIPELINE\n",
    "def main():\n",
    "    print(\"=\"*60)\n",
    "    print(\"EFFICIENTNETB0 TRAINING PIPELINE\")\n",
    "    print(\"=\"*60)\n",
    "    \n",
    "    # Load datasets\n",
    "    print(\"\\n1. Loading datasets...\")\n",
    "    train_ds, val_ds, test_ds, num_classes = create_datasets(DATA_DIR)\n",
    "    print(f\"Number of classes: {num_classes}\")\n",
    "    \n",
    "    # Build model\n",
    "    print(\"\\n2. Building model...\")\n",
    "    model = build_model(num_classes)\n",
    "    print(f\"Total parameters: {model.count_params():,}\")\n",
    "    \n",
    "    # Initial training\n",
    "    print(\"\\n3. Initial training...\")\n",
    "    history = train_model(model, train_ds, val_ds)\n",
    "    \n",
    "    # Evaluate base model\n",
    "    # print(\"\\n4. Evaluating base model...\")\n",
    "    # evaluate_model(model, test_ds)\n",
    "    \n",
    "    # Apply pruning\n",
    "    print(\"\\n5. Applying pruning...\")\n",
    "    model_pruned, prune_history = apply_pruning(model, train_ds, val_ds)\n",
    "    evaluate_model(model_pruned, test_ds)\n",
    "    \n",
    "    # Save pruned model\n",
    "    print(\"\\nSaving pruned model...\")\n",
    "    model_pruned.save('pruned_model', save_format='tf')\n",
    "    \n",
    "    # Apply QAT\n",
    "    print(\"\\n6. Applying Quantization Aware Training...\")\n",
    "    model_qat, qat_history = apply_qat(model_pruned, train_ds, val_ds)\n",
    "    evaluate_model(model_qat, test_ds)\n",
    "    \n",
    "    # Convert to TFLite (direct conversion without intermediate save)\n",
    "    print(\"\\n7. Converting to TFLite...\")\n",
    "    \n",
    "    # Create representative dataset for full integer quantization\n",
    "    rep_data_gen = representative_data_gen(train_ds)\n",
    "    \n",
    "    # Convert directly to TFLite (this avoids the tracking issue)\n",
    "    tflite_model = convert_to_tflite(model_qat, rep_data_gen, quantize=True)\n",
    "    \n",
    "    # Save TFLite model\n",
    "    with open('model_quantized.tflite', 'wb') as f:\n",
    "        f.write(tflite_model)\n",
    "    \n",
    "    tflite_size = len(tflite_model) / 1024 / 1024\n",
    "    print(f\"TFLite model size: {tflite_size:.2f} MB\")\n",
    "    \n",
    "    # Optionally try to save the QAT model (may fail, but TFLite is already saved)\n",
    "    print(\"\\n8. Attempting to save QAT model...\")\n",
    "    save_qat_model(model_qat, 'final_model')\n",
    "    \n",
    "    # Evaluate TFLite model\n",
    "    print(\"\\n9. Evaluating TFLite model...\")\n",
    "    evaluate_tflite(tflite_model, test_ds)\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # Verify TensorFlow Model Optimization toolkit is installed\n",
    "    try:\n",
    "        import tensorflow_model_optimization as tfmot\n",
    "    except ImportError:\n",
    "        print(\"Please install: pip install tensorflow-model-optimization\")\n",
    "        exit(1)\n",
    "    \n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a4129e3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf-env-esp32",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
